At the highest level, Kubernetes is an orchestrator of containerized apps. Ideally microservice apps. Microservice app is just a fancy name for an application that’s made up of lots of small and independent parts - we sometimes call these small parts services. 
These small independent services work together to create a meaningful/useful app.


In the real world, a football (soccer) team is made up of individuals. No two are the same, and each has a different role to play in the team. 
Some defend, some attack, some are great at passing, some are great at shooting…. Along comes the coach, and he or she gives everyone a position and organizes them into a team with a plan.



At the time of writing, the best way to package and deploy a Kubernetes application is via something called a Deployment. 
With Deployments, we start out with our application code and we containerize it. Then we define it as a Deployment via a YAML or JSON manifest file. This manifest file tells Kubernetes two important things:
What our app should look like – what images to use, ports to expose, networks to join, how to perform update etc.
How many replicas of each part of the app to run (scale)


master:


kube-apiserver

The API Server (apiserver) is the frontend into the Kubernetes control plane. You can think of the API server as the brains of the cluster. By default, it exposes a RESTful endpoint on port 443

kube-apiserver 支持同时提供 https（默认监听在 6443 端口）和 http API（默认监听在 127.0.0.1 的 8080 端口），其中 http API 是非安全接口，不做任何认证授权机制，不建议生产环境启用。两个接口提供的 REST API 格式相同


在实际使用中，通常通过 kubectl 来访问 apiserver，也可以通过 Kubernetes 各个语言的 client 库来访问 apiserver。在使用 kubectl 时，打开调试日志也可以看到每个 API 调用的格式，比如
kubectl --v=8 get pods


可通过 
kubectl api-versions 
和 
kubectl api-resources
查询 Kubernetes API 支持的 API 版本以及资源对象












The cluster store
If the API Server is the brains of the cluster, the cluster store is its memory, The cluster store is based on etcd, the popular distributed, consistent and watchable key-value store.


kube-controller-manager
They tend to sit in loops and watch for changes – the aim of the game is to make sure the current state of the cluster matches the desired state (more on this shortly).


kube-scheduler
watches for newly created Pods with no assigned node, and selects a node for them to run on

cloud-controller-manager







node:

kubelet

kube-proxy

Container runtime



每台机器上都运行一个 kube-proxy 服务，它监听 API server 中 service 和 endpoint 的变化情况，并通过 iptables 等来为服务配置负载均衡（仅支持 TCP 和 UDP）.
kube-proxy 可以直接运行在物理机上，也可以以 static pod 或者 daemonset 的方式运行.





每个Node节点上都运行一个 Kubelet 服务进程，默认监听 10250 端口，接收并执行 Master 发来的指令，管理 Pod 及 Pod 中的容器。每个 Kubelet 进程会在 API Server 上注册所在Node节点的信息，定期向 Master 节点汇报该节点的资源使用情况，并通过 cAdvisor 监控节点和容器的资源.





In Kubernetes, the two concepts work like this:
1. We declare the desired state of our application (microservice) in a manifest file
2. We POST it the API server
3. Kubernetes stores this in the cluster store as the application’s desired state
4. Kubernetes deploys the application on the cluster
5. Kubernetes implements watch loops to make sure the cluster doesn’t vary from desired state
